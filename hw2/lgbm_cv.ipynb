{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4321700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8526e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/featurized.parquet')\n",
    "\n",
    "# Ranking requires sorting by group\n",
    "sorted_df = df.sort_values(by='msno').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8551e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_user_auc(y_true, y_pred, group):\n",
    "    out = 0.\n",
    "    i = 0\n",
    "    valid_user_count = 0\n",
    "    for j in np.cumsum(group):\n",
    "        if j - i < 2 or len(set(y_true[i:j])) < 2:\n",
    "            # Intractable, skip group\n",
    "            continue\n",
    "        out += roc_auc_score(y_true[i:j], y_pred[i:j])\n",
    "        valid_user_count += 1\n",
    "        i = j\n",
    "    out /= valid_user_count\n",
    "    \n",
    "    return out\n",
    "\n",
    "def lgb_mean_user_auc(y_pred, train_data):\n",
    "    out = mean_user_auc(train_data.label, y_pred, train_data.group)\n",
    "    return 'mean_user_auc', out, True\n",
    "\n",
    "\n",
    "def train_lgb(df, params):\n",
    "    X = df.iloc[:, 1:-1]\n",
    "    groups = df.iloc[:, 0]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    preds = np.zeros_like(y, dtype=float)\n",
    "    models = []\n",
    "    for train_idx, test_idx in GroupKFold(5).split(X, y, groups):\n",
    "        train_group = groups.iloc[train_idx].groupby(groups.iloc[train_idx].values).count().tolist()\n",
    "        test_group = groups.iloc[test_idx].groupby(groups.iloc[test_idx].values).count().tolist()\n",
    "\n",
    "        train_ds = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx], group=train_group)\n",
    "        test_ds = lgb.Dataset(X.iloc[test_idx], y.iloc[test_idx], group=test_group)\n",
    "\n",
    "        # We can use early stopping because of the holdout set existence (\"./data/test.csv\")\n",
    "        # In a real world application we would tune the model on a CV and \n",
    "        # measure the best model performance on the holdout\n",
    "        # However, 100 boosting rounds is too few and the model is still underfit\n",
    "        model = lgb.train(\n",
    "            params, \n",
    "            train_set=train_ds, \n",
    "            valid_sets=test_ds, \n",
    "            fobj=None, \n",
    "            feval=lgb_mean_user_auc, \n",
    "            verbose_eval=5, \n",
    "            early_stopping_rounds=25\n",
    "        )\n",
    "        models.append(model)\n",
    "        preds[test_idx] = model.predict(X.iloc[test_idx])\n",
    "        \n",
    "    return preds, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529b74a",
   "metadata": {},
   "source": [
    "## Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f31ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB params from kaggle, slightly modified\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'None',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.2 ,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 100,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 256,\n",
    "    'num_rounds': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb50fd47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.259925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.639422\n",
      "[10]\tvalid_0's mean_user_auc: 0.645121\n",
      "[15]\tvalid_0's mean_user_auc: 0.647666\n",
      "[20]\tvalid_0's mean_user_auc: 0.64917\n",
      "[25]\tvalid_0's mean_user_auc: 0.650575\n",
      "[30]\tvalid_0's mean_user_auc: 0.651076\n",
      "[35]\tvalid_0's mean_user_auc: 0.651168\n",
      "[40]\tvalid_0's mean_user_auc: 0.651078\n",
      "[45]\tvalid_0's mean_user_auc: 0.65108\n",
      "[50]\tvalid_0's mean_user_auc: 0.650854\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[33]\tvalid_0's mean_user_auc: 0.65138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.277483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.63767\n",
      "[10]\tvalid_0's mean_user_auc: 0.642331\n",
      "[15]\tvalid_0's mean_user_auc: 0.645261\n",
      "[20]\tvalid_0's mean_user_auc: 0.646927\n",
      "[25]\tvalid_0's mean_user_auc: 0.647716\n",
      "[30]\tvalid_0's mean_user_auc: 0.648157\n",
      "[35]\tvalid_0's mean_user_auc: 0.648419\n",
      "[40]\tvalid_0's mean_user_auc: 0.648462\n",
      "[45]\tvalid_0's mean_user_auc: 0.648626\n",
      "[50]\tvalid_0's mean_user_auc: 0.648456\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[41]\tvalid_0's mean_user_auc: 0.648676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.330657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.639359\n",
      "[10]\tvalid_0's mean_user_auc: 0.645089\n",
      "[15]\tvalid_0's mean_user_auc: 0.648028\n",
      "[20]\tvalid_0's mean_user_auc: 0.649791\n",
      "[25]\tvalid_0's mean_user_auc: 0.650263\n",
      "[30]\tvalid_0's mean_user_auc: 0.650451\n",
      "[35]\tvalid_0's mean_user_auc: 0.65089\n",
      "[40]\tvalid_0's mean_user_auc: 0.650706\n",
      "[45]\tvalid_0's mean_user_auc: 0.650915\n",
      "[50]\tvalid_0's mean_user_auc: 0.650692\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[37]\tvalid_0's mean_user_auc: 0.651115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.275209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.636178\n",
      "[10]\tvalid_0's mean_user_auc: 0.642076\n",
      "[15]\tvalid_0's mean_user_auc: 0.644857\n",
      "[20]\tvalid_0's mean_user_auc: 0.646914\n",
      "[25]\tvalid_0's mean_user_auc: 0.647965\n",
      "[30]\tvalid_0's mean_user_auc: 0.64833\n",
      "[35]\tvalid_0's mean_user_auc: 0.649095\n",
      "[40]\tvalid_0's mean_user_auc: 0.649119\n",
      "[45]\tvalid_0's mean_user_auc: 0.649523\n",
      "[50]\tvalid_0's mean_user_auc: 0.649354\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[47]\tvalid_0's mean_user_auc: 0.649655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.315421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.639239\n",
      "[10]\tvalid_0's mean_user_auc: 0.645243\n",
      "[15]\tvalid_0's mean_user_auc: 0.647813\n",
      "[20]\tvalid_0's mean_user_auc: 0.649942\n",
      "[25]\tvalid_0's mean_user_auc: 0.651406\n",
      "[30]\tvalid_0's mean_user_auc: 0.651232\n",
      "[35]\tvalid_0's mean_user_auc: 0.650999\n",
      "[40]\tvalid_0's mean_user_auc: 0.65122\n",
      "[45]\tvalid_0's mean_user_auc: 0.650813\n",
      "[50]\tvalid_0's mean_user_auc: 0.649839\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[28]\tvalid_0's mean_user_auc: 0.651464\n"
     ]
    }
   ],
   "source": [
    "preds, models = train_lgb(sorted_df, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560ca79",
   "metadata": {},
   "source": [
    "Померяем ROC-AUC (как в соревновании на кэгле) и Mean User ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b22c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.678172545848034"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OOF ROC-AUC\n",
    "roc_auc_score(sorted_df.iloc[:, -1], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c2995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506320865055217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean User ROC-AUC\n",
    "mean_user_auc(sorted_df.iloc[:, -1], preds, sorted_df.groupby('msno')['song_id'].count().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce70bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oof_lgbm_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cd8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (hse_recsys)",
   "language": "python",
   "name": "pycharm-ecd2752e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}