{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4321700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8526e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/featurized.parquet')\n",
    "\n",
    "# Ranking requires sorting by group\n",
    "sorted_df = df.sort_values(by='msno').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8551e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_user_auc(y_true, y_pred, group):\n",
    "    out = 0.\n",
    "    i = 0\n",
    "    valid_user_count = 0\n",
    "    for j in np.cumsum(group):\n",
    "        if j - i < 2 or len(set(y_true[i:j])) < 2:\n",
    "            # Intractable, skip group\n",
    "            continue\n",
    "        out += roc_auc_score(y_true[i:j], y_pred[i:j])\n",
    "        valid_user_count += 1\n",
    "        i = j\n",
    "    out /= valid_user_count\n",
    "    \n",
    "    return out\n",
    "\n",
    "def lgb_mean_user_auc(y_pred, train_data):\n",
    "    out = mean_user_auc(train_data.label, y_pred, train_data.group)\n",
    "    return 'mean_user_auc', out, True\n",
    "\n",
    "\n",
    "def train_lgb(df, params):\n",
    "    X = df.iloc[:, 1:-1]\n",
    "    groups = df.iloc[:, 0]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    preds = np.zeros_like(y, dtype=float)\n",
    "    models = []\n",
    "    for train_idx, test_idx in GroupKFold(5).split(X, y, groups):\n",
    "        train_group = groups.iloc[train_idx].groupby(groups.iloc[train_idx].values).count().tolist()\n",
    "        test_group = groups.iloc[test_idx].groupby(groups.iloc[test_idx].values).count().tolist()\n",
    "\n",
    "        train_ds = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx], group=train_group)\n",
    "        test_ds = lgb.Dataset(X.iloc[test_idx], y.iloc[test_idx], group=test_group)\n",
    "\n",
    "        # We can use early stopping because of the holdout set existence (\"./data/test.csv\")\n",
    "        # In a real world application we would tune the model on a CV and \n",
    "        # measure the best model performance on the holdout\n",
    "        # However, 100 boosting rounds is too few and the model is still underfit\n",
    "        model = lgb.train(\n",
    "            params, \n",
    "            train_set=train_ds, \n",
    "            valid_sets=test_ds, \n",
    "            fobj=None, \n",
    "            feval=lgb_mean_user_auc, \n",
    "            verbose_eval=5, \n",
    "            early_stopping_rounds=25\n",
    "        )\n",
    "        models.append(model)\n",
    "        preds[test_idx] = model.predict(X.iloc[test_idx])\n",
    "        \n",
    "    return preds, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529b74a",
   "metadata": {},
   "source": [
    "## Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f31ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB params from kaggle, slightly modified\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'None',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.2 ,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 100,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 256,\n",
    "    'num_rounds': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb50fd47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.648818\n",
      "[10]\tvalid_0's mean_user_auc: 0.652595\n",
      "[15]\tvalid_0's mean_user_auc: 0.654164\n",
      "[20]\tvalid_0's mean_user_auc: 0.655628\n",
      "[25]\tvalid_0's mean_user_auc: 0.655526\n",
      "[30]\tvalid_0's mean_user_auc: 0.655562\n",
      "[35]\tvalid_0's mean_user_auc: 0.655026\n",
      "[40]\tvalid_0's mean_user_auc: 0.654969\n",
      "[45]\tvalid_0's mean_user_auc: 0.654528\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's mean_user_auc: 0.655895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.263712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.644931\n",
      "[10]\tvalid_0's mean_user_auc: 0.648527\n",
      "[15]\tvalid_0's mean_user_auc: 0.650729\n",
      "[20]\tvalid_0's mean_user_auc: 0.651409\n",
      "[25]\tvalid_0's mean_user_auc: 0.651837\n",
      "[30]\tvalid_0's mean_user_auc: 0.65165\n",
      "[35]\tvalid_0's mean_user_auc: 0.651303\n",
      "[40]\tvalid_0's mean_user_auc: 0.651079\n",
      "[45]\tvalid_0's mean_user_auc: 0.651221\n",
      "[50]\tvalid_0's mean_user_auc: 0.651552\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[28]\tvalid_0's mean_user_auc: 0.651916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.271173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.649525\n",
      "[10]\tvalid_0's mean_user_auc: 0.652198\n",
      "[15]\tvalid_0's mean_user_auc: 0.652867\n",
      "[20]\tvalid_0's mean_user_auc: 0.653329\n",
      "[25]\tvalid_0's mean_user_auc: 0.653784\n",
      "[30]\tvalid_0's mean_user_auc: 0.654665\n",
      "[35]\tvalid_0's mean_user_auc: 0.654707\n",
      "[40]\tvalid_0's mean_user_auc: 0.654195\n",
      "[45]\tvalid_0's mean_user_auc: 0.654314\n",
      "[50]\tvalid_0's mean_user_auc: 0.654078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[32]\tvalid_0's mean_user_auc: 0.654844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.289851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.646433\n",
      "[10]\tvalid_0's mean_user_auc: 0.651047\n",
      "[15]\tvalid_0's mean_user_auc: 0.653625\n",
      "[20]\tvalid_0's mean_user_auc: 0.655441\n",
      "[25]\tvalid_0's mean_user_auc: 0.655438\n",
      "[30]\tvalid_0's mean_user_auc: 0.65533\n",
      "[35]\tvalid_0's mean_user_auc: 0.655184\n",
      "[40]\tvalid_0's mean_user_auc: 0.65503\n",
      "[45]\tvalid_0's mean_user_auc: 0.655101\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's mean_user_auc: 0.655668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.308143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dmitry/.conda/envs/hse_recsys/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[5]\tvalid_0's mean_user_auc: 0.64813\n",
      "[10]\tvalid_0's mean_user_auc: 0.651782\n",
      "[15]\tvalid_0's mean_user_auc: 0.653855\n",
      "[20]\tvalid_0's mean_user_auc: 0.65525\n",
      "[25]\tvalid_0's mean_user_auc: 0.655511\n",
      "[30]\tvalid_0's mean_user_auc: 0.654815\n",
      "[35]\tvalid_0's mean_user_auc: 0.65416\n",
      "[40]\tvalid_0's mean_user_auc: 0.653746\n",
      "[45]\tvalid_0's mean_user_auc: 0.653606\n",
      "[50]\tvalid_0's mean_user_auc: 0.653556\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's mean_user_auc: 0.655511\n"
     ]
    }
   ],
   "source": [
    "preds, models = train_lgb(sorted_df, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560ca79",
   "metadata": {},
   "source": [
    "Померяем ROC-AUC (как в соревновании на кэгле) и Mean User ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b22c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6812341920424946"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OOF ROC-AUC\n",
    "roc_auc_score(sorted_df.iloc[:, -1], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c2995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6549377243665163"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean User ROC-AUC\n",
    "mean_user_auc(sorted_df.iloc[:, -1], preds, sorted_df.groupby('msno')['song_id'].count().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce70bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oof_lgbm_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cd8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (hse_recsys)",
   "language": "python",
   "name": "pycharm-ecd2752e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}